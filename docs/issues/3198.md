# #3198: Unroll constant-sized loops

- **URL:** https://github.com/WebAssembly/binaryen/issues/3198
- **Author:** MaxGraey
- **Created:** 2020-10-07
- **Updated:** 2020-10-13

## Description

Sometimes it could greatly improve code size. Let's look at real world example from KhronosGroup's project (AssemblyScript):
```ts
 for (let bits: u32 = 0; bits < 4; bits++) {
    const a = (bits & 1) ? 0x1FF : 0;
    const b = (bits & 2) ? 0x116 : 0;
    for (let trit: u32 = 0; trit < 3; trit++) {
      const i = (trit << 2) | bits;
      const u = (a & 0x80) | (((trit * 93 + b) ^ a) >> 2);
      store<u8>(i, u, 0x40);
    }
 }
```
this nested loops could be completely unrolled with partially evaluation to:
```ts
// bits = 0
store<u8>(0, 0,  0x40);
store<u8>(4, 23, 0x40);
store<u8>(8, 46, 0x40);
// bits = 1
store<u8>(1, 255, 0x40);
store<u8>(5, 232, 0x40);
store<u8>(9, 209, 0x40);
// bits = 2
store<u8>(2, 69, 0x40);
store<u8>(6, 82, 0x40);
store<u8>(10, 107, 0x40);
// bits = 3
store<u8>(3, 186, 0x40);
store<u8>(7, 163, 0x40);
store<u8>(11, 139, 0x40);
```
next step it could sort stores/loads in order by access and merge as:
```ts
store<u32>(0, (186 << 24) | (69 << 16) | (255 << 8) | (0 << 0), 0x40);
store<u32>(4, (163 << 24) | (82 << 16) | (232 << 8) | (23 << 0), 0x40);
store<u32>(8, (139 << 24) | (107 << 16) | (209 << 8) | (46 << 0), 0x40);
```
finally after constant folding:
```ts
store<u32>(0x40, 0xba45ff00);
store<u32>(0x44, 0xa352e817);
store<u32>(0x48, 0x8b6bd12e);
```

before `116` bytes
after: `35` bytes

of course it's not always may lead to size improvements. So perhaps need some cost prediction function before try to apply this unrolling. WDYT?

## Comments (4)

### kripken (2020-10-08)

This is definitely a case that shows how great this can be. The cost prediction would be pretty hard to do, though, I worry. But it's worth thinking about.

One specific thing I'd be curious about is how LLVM handles this. That is, to run equivalent code through the LLVM optimizer and see which passes are crucial to improving it (I'm assuming it succeeds at getting to the optimal result).

Separately, the sorting idea is a very good one, I think that would be straightforward to do, and potentially pretty useful in code like this.

---

### MaxGraey (2020-10-08)

> One specific thing I'd be curious about is how LLVM handles this

Yes, LLVM unrolled this, but only when optimize for speed (-O2/O3): https://godbolt.org/z/4vr1KT
So it seems LLVM hasn't cost function for this and always try to do this for any constant sized loop for all size which less some thresholding. 

> The cost prediction would be pretty hard to do, though, I worry

This may be a very stupid idea and it won't actually work. But here's how we could roughly estimate cost:

1) Check size constant and start analysing after some threshold (for example 128).
2) Starts calculate costs of the loop's body as usual with the only difference that invariants, consts and inductive variables have zero costs or all expressions which contain inductive variables except exprs with side effects equal to cost of constant literal.
3) Multiply total sum cost by size of loop (approxUnrolledCost) and compare this size with normal calculated cost for whole loop (normalCost) (when invariants and inductives have normal costs). Compare this sum of costs and if `approxUnrolledCost <  normalCost / someEmpiricalFactor` we start unrolling and optimizing this loop. Ideally it will be done in non-destructive way with rollback if this transform can't take size benefits.

---

### kripken (2020-10-12)

Thanks @MaxGraey , interesting. I'd also be curious which LLVM passes specifically help after the unrolling.

The cost idea sounds interesting, might be work exploring that space. Another idea I've had, but have not had time to do, is speculative optimization - run the optimization, and normal general optimizations after it, and if it didn't help, roll back all the changes (very easy to do with inlining, for example, but should be possible with something like this too).

---

### MaxGraey (2020-10-13)

Exactly! Speculative optimization is exactly what I meant in p.3 and probably it will enough with size tresholding p.1 for POC. Afterwards we could try some more sophisticated approach with approx cost measurements.

---

